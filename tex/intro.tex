%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter01.tex for SJTU Master Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{绪论}
\label{chap:intro}


\section{研究背景和意义}
近年来，NUMA架构的服务器逐渐普及，它的出现解决了对称多处理器（symmetric multiprocessor architecture，SMP）架构在可扩展性方面的局限性，所以已经成为现代服务器架构设计中的一种趋势和规范。良好的可扩展性使得单个NUMA架构的机器上可以轻易集成更多的计算核心，更大容量的物理内存和更大的内存访问带宽，使得应用程序可以更好利用线程级别的并行性。计算核心通常被组织成一个计算节点（node）集合，每个计算节点包括若干计算核心，一块物理内存和多层缓存，计算节点之间通过高速芯片间通信介质连接。在这种架构的机器中，某个计算核心访问其所在的计算节点的本地内存，尤其是本地共享缓存的速度通常是访问在其他计算节点上的内存或缓存的速度的数倍，也就是说NUMA结构的机器中内存访问存在非一致性时延。另外，在同一个计算节点内部，由于缓存的的分层设计，同一个计算核心访问本地计算节点的不同层次的缓存也会有显著的非一致性时延。

对于大型内存数据库(例如Microsoft SQL server）和处理引擎（例如spark）等通过高并发来处理大规模海量数据的应用来说，随着数据规模的指数增长，必然需要进一步地扩展，通过更高程度的并发来满足需求。而NUMA架构提供的更多的核，更大的内存容量和更大的内存访问带宽使得这些应用可以生成更多的线程，并将这些线程分布到所有的NUMA计算核心上来尽可能地利用所有NUMA节点的计算和存储资源。另一方面，NUMA架构本身存在的内存访问的非一致性时延以及NUMA节点之间的有限的带宽资源使得系统性能存在很大的不确定性，也对系统的线程调度和内存管理提出了新的挑战。这些共享内存的应用中线程之间通常存在大量的共享数据，数据在内存及缓存中的存储位置和及访问该数据的线程的在机器上执行位置决定了数据访问的时延和最大带宽，因而对于系统的整体性能有很大影响。合理的内存管理和线程调度能够充分利用数据访问的局部性提高性能，而不合适的内存管理和线程调度策略可能会造成整体性能的严重损失。

通过挖掘应用的数据访问特征，比如线程对数据访问范围和访问频率及线程之间的数据共享范围和共享频率来建立线程之间的亲和性（thread affinity）及线程与数据之间的亲和性（data affinity），将共享数据多共享频率多的线程调度到相同的NUMA节点上，同时将数据放置到最常被访问的NUMA节点上，可以充分利用数据访问的局部性来增加缓存命中率，降低数据访问延迟，减少NUMA节点间通信介质上的缓存一致数据流，进而提高应用的整体性能。另外，线程之间共享的数据中有部分特殊数据不能被多个线程同时访问并通常需要一种同步机制来防止其被同时访问更新，尽管近年来事务内存（transaction memory）开始流行，但是对于多数高并发的应用来说，在高度竞争地情况下锁依然是一种最基本最重要地同步机制。一方面，锁本身及其保护的数据都是线程之间的共享数据，所以线程调度和内存管理都会对其性能有重要影响。另一方面，锁保护的数据只能在线程间串行访问，这使得锁很容易成为应用性能和进一步扩展的瓶颈，NUMA因素的出现进一步加剧了这种瓶颈，也对锁的设计提出了新的挑战。

在传统地SMP架构中，基于队列地锁，例如CLH和MCS锁，一直是许多锁集中的高性能系统地不二之选。这些基于队列的锁被选择的主要原因是，他们将所有等待访问关键区域的线程排成先进先出的队列，每个线程在被分隔开的内存区域等待锁，从而减少了总的用于维持缓存一致性的数据流，提高了系统的总体性能和可扩展性。然而在NUMA架构中，这些基于队列的锁的性能显著下降，这主要是由NUMA架构机器的物理架构决定的。由于传统的基于队列的锁不知道NUMA架构硬件层面的内存及缓存的非一致特性，为了保持先来先服务的锁传递顺序，就会产生锁在各个NUMA计算节点之间的随意传递，而锁及其保护的数据在NUMA节点之间的传递需要时间通常会是在同一个NUMA节点内传递时间的数倍，从而加长锁传递的时间和关键区域的执行时间，增加时延，减小吞吐率，使得性能会有显著下降。

由于锁及其保护的关键数据在线程共享数据之间的占比一般较小，所以内存管理对其性能的影响不大；而线程调度/放置决定着层级锁所能挖掘和利用的数据访问局部性的多寡，所以其对层级锁的性能有很重要的影响，选择或设计合适地线程放置策略对于层级锁的性能非常关键，因而本文主要从线程放置策略的角度优化层级锁的性能和其他特性。本文的研究基于现有NUMA架构下的锁的相关研究，以NUMA感知的层级锁为基础，分析了层级锁中现有线程放置策略的优劣，保持和利用现有策略的优势，解决其中存在的不能同时兼顾性能和公平性，不能适应竞争强度变化等缺陷。

NUMA架构是可预见的未来大型计算机硬件架构设计的大趋势，而随着医疗，交通，社交等领域产生的大数据的爆发式的增长，以及云计算等共享计算资源模式的快速发展，大型应用对于性能，可扩展性和公平性等方面的要求必然进步提高。本文的研究使得层级锁能够更好地适应未来软硬件的特性和需求变化，更好地服务于当下和未来相关领域的发展。总而言之，NUMA架构的出现解决了大型计算机硬件层面的扩展性问题，使得高性能共享内存应用能够进一步地扩展来满足日益增长地数据处理地需要；层级锁的出现改善了应用中使用地传统锁在NUMA架构下存在的性能不足问题，但是也带来了公平性不足的新问题；而本文的研究从线程调度/放置的角度进一步的优化现有的层级锁设计，使其在保持性能和可扩展性的前提下在一定程度上保证公平性。考虑到NUMA架构的机器的不断普及以及发展趋势和公有云等对公平性，性能和可扩展性都有很高要求的应用场景的不断增多，本文的研究将使得层级锁能够更好适应这些应用场景地需求，并且在可预见地未来有更大应用前景。
\section{国内外研究现状6.5}
针对上节提到的NUMA架构下传统锁及关键区域在计算节点之间随意迁移导致的锁性能下降问题，目前已有多种解决方案，除了事务性内存等无锁解决方案以外，现有其它解决方案大致可以分为以下四类，即委托执行，线程聚类，线程迁移，NUMA感知的层级锁。
\subsection{委托执行}
为了避免锁在NUMA节点之间传递的巨大开销，要执行关键区域的线程可以委托一个或几个专门的核代为执行，从而完全避免锁的传递所造成的缓存数据的同步及由此带来的时延和吞吐率损失，因为锁及其保护的数据始终在对应核的缓存中。这种方案的代价是需要额外的线程间通信并且至少需要一个线程专门执行关键区域。RCL（remote core locking）就是委托执行的一种，RCL的作者观察到大多数多线程应用并不需要或者不能扩展到现代多核机器的所有核上，所以让某几个特定的核专门执行关键区域及利用了空余的核由可能会带来潜在的性能提升，要执行关键区域的线程不需要通过竞争锁来进入关键区域，而是通过优化后的远程过程调用委托特定核完成关键区域的执行从而来完全避免锁及其保护的数据的传递。委托执行本质上是在迁移关键区域的执行，相比传统锁，它能在某些特定应用中限制高度竞争情况下应用性能的崩溃，但是它最大的缺陷是需要修改使用传统锁的历史遗留代码，原有代码中的关键区域需要额外的技术和时间被识别和修改之后才能利用委托执行的的高性能。
\subsection{线程聚类}
线程聚类是把同一个应用的线程或者竞争同一个锁的线程调度到同一个NUMA节点上。这样做的好处是所有的数据都存在于本地内存或者缓存中，并且将锁的传递限制在同一个NUMA节点内部，避免锁在NUMA节点之间传递的开销。该方案本质山是通过建立线程间的亲和性来挖掘和利用数据访问的局部性，所以也常被用在一般的共享数据中将有共享内存数据的线程放置在同一个计算节点上来最大化缓存的共享和复用，由于一般的共享数据并不像锁一样在所有线程间共享，所以这种情况下还涉及线程间共享数据及其共享范围的检测。线程聚类能显著改善线程较少的小规模应用的性能，但是对于具有大量线程的高并发应用程序而言，其所拥有的线程数通常远大于单核计算节点上上的计算核心，按照线程聚类的方法所有线程都会被分到一个聚类中，因而会产生负载不均衡的问题，同时并行性也被牺牲了，除此以外也会带来拿锁者被抢占或者等待者被抢占等新问题，最终的结果可能得不偿失，所以线程聚类一般只适用于线程数量较少的小规模应用。
\subsection{线程迁移}
在系统运行的同时，将锁的等待者动态地迁移到锁的持有者当前所在NUMA节点上，从而避免锁及关键区域的数据在NUMA节点之间的传递。这种方案主要基于以下观察，即锁集中的多线程应用的性能对于线程在NUMA节点之间的分布高度敏感但是操作系统的调度器感知不到锁在线程之间的竞争自然不能将锁的竞争因素加入到调度器地调度策略中，所以线程迁移可以看作是在考虑锁竞争因素的情况下对操作系统默认调度器调度策略的一种补充。shuffling是通过线程迁移来提高锁的性能的一种，它定期地将线程按照其“到达时间”（线程请求锁的时间）来排序；然后将”到达时间“接近的线程分到同一组中，每组的线程数量大致等于单个NUMA节点上的计算核心数；最后将分到同一组的线程迁移到同一个NUMA节点上去执行。因为连续请求锁的线程被分为同一组并且放到同一个节点上执行，所以锁在节点之间的迁移频率被显著降低；另外放置在每个计算节点上的线程数不超过该节点上的计算核心数又能避免负载不均衡及抢占等问题。线程迁移能够有效地减小锁及关键区域的迁移频率，提高系统的整体性能，并且不改变原有锁的传递顺序，代价则是较为频繁大量的线程迁移及其带来的潜在缓存污染等问题。
\subsection{NUMA感知的层级锁}
层级锁利用多层的锁来对照下层的NUMA结构，将锁的竞争分割在不同的NUMA节点或者同一个NUMA节点内部不同的计算核心上，从而减少锁及关键区域数据在NUMA节点间的随意迁移频率。与其他解决方案的主要不同之处在于层级锁不是按照锁的请求顺序来传递的，层级锁本质上是通过牺牲短期公平性来换取减少锁的跨界点传递频率提高锁的吞吐率的。具体来说，在层级锁中，锁的持有者会优先将锁传递给当前节点上的最早的请求者而不是所有节点范围内的最早的请求者，只有当前节点上没有请求者时才会传给其他节点上的请求者。另外为了避免饥饿（starvation）及深度不公平等问题，层级锁中通常会设定一个上限来限制其在同一个节点内的连续传递次数。有了这个上限的限之后，层级锁的锁传递顺序可以描述为，锁的持有者将其传给一个本地的最早请求者当且仅当以下两个条件同时满足：
\begin{itemize}
\item  本地节点当前至少有一个请求者；
\item  所在本地节点的传递次数还未超过预先设定的上限值；
\end{itemize}
层级锁包括lock cohorting， HMCS锁，AHMCS锁核HMCS-T等。lock cohorting的设计基于一个全局锁和每个NUMA节点上的本地锁。全局锁和本地锁都可以任何传统的锁（MCS, CLH，门票锁，自旋锁等）。全局锁在所有节点之间共享，它的主要功能时将竞争分隔到各个节点之内。一个本地锁只在本地节点里边的线程之间共享并且用来同步本地节点内的线程。一个线程只有同时拿到全局锁何其所在节点的本地锁才可以访问关键区域。由于只有全局锁会在节点之间传递并且该传递频率因为竞争分割的关系会很低，所以锁的整体性能显著提高。HMCS将lock cohorting的思想推广到了具有深层NUMA架构的机器中，从而能够潜在地发掘和利用各个NUMA层次地局部性获取更高地性能。HMCS适合高竞争地情况，但是竞争较小或者没有竞争地情况下，其多层地锁架构会带来较大地时延，AHMCS针对该问题使用多个互相正交地策略来同时达到高竞争时地高吞吐和低竞争时地低时延。HMCS-T保持了HMCS地高性能，并且通过超时机制来使HMCS具备放弃竞争特性。上述层级锁具有不同地其他方面地特征和创新，但它们都是通过竞争分割降低锁地跨节点传递频率来提高锁地整体吞吐率的。
\section{研究内容和结构安排}
\subsection{研究基础}
本文针对层级锁的性能和长期公平性受线程放置策略影响较大的特点，通过分析现有线程调度策略的优缺点，在此基础上充分利用现有策略的优势，改进其不足，从而从线程放置的角度进一步地优化层级锁，使其能够同时保证高性能和稳定可靠地长期公平性，更好地满足NUMA架构下相关应用场景地需求。层级锁中现有地线程放置策略主有以下三种：自由放置（free-range），紧凑放置（compact）和平均放置（even）。
\begin{itemize}
\item 自由放置，即操作系统调度器地默认线程调度策略。应用程序对于线程地放置没有任何限制，线程的迁移调度全部交给操作系统地调度器来完成。自由放置能够充分利用现代操作系统激进的线程迁移来达到更好负载均衡和其他调度策略。但是对于层级锁来说，由于默认的调度器并不知道线程和应用程序大的所属关系，也不知道线程之间的锁竞争关系，简单的负载均衡很容易将同一个应用的线程分散到多个节点上去从而减少层级锁所能挖掘利用的局部性，同时也可能带来锁的持有者被抢占或者等待者被抢占等问题。
\item 紧凑放置，由于层级锁偏向于寻找最近的等待者完成锁传递，因此最自然的线程放置策略是将线程尽可能地放得紧凑，这也是目前大多数层级锁中的默认线程放置策略。具体来说，新的线程会尽可能地被放置在当前NUMA节点地某个可用计算核心上，只有当前地NUMA节点上没有可用地计算核心时，新的线程才会被放置到一个新NUMA节点地某个专用计算核心上。相比操作系统默认地线程调度策略，紧凑策略更好地控制了CPU资源地分配，保存了更多地局部性，够获得尽可能高地性能；同时将每个线程绑定到一个专用的核上也能避免线程抢占带来的问题。但是，紧凑策略会导致线程在NUMA节点之间分布的不均，再加上层级锁锁传递策略的本地偏好的特性，进而不能保证层级锁地长期公平性（long-term fairness），即从长远看系统总的吞吐率很高，但是单个线程的吞吐率之间差异很大。

\item 平均放置，另一种主要的线程放置策略是平均放置，也就是说线程被平均地放置在所有的NUMA节点上。由于每个节点上运行相同数量的线程，所以每个节点具有相同的将锁保持在其上的能力，因此平均放置地策略能够很好地保证层级锁地长期公平性。但是在锁地竞争不足时相比紧凑策略会有很大地吞吐率损失。这主要是因为平均放置使得线程分布更为分散，而相同的竞争能力又使得锁很容易在NUMA节点之间随意传递，所以在竞争不足时层级锁不能有效地挖掘同一个NUMA节点上地线程之间地局部性。
\end{itemize}
\subsection{研究内容}
性能和公平性是任何锁设计中最重要的两个指标，而目前的层级锁设计及其线程放置策略或者不能保证最佳的性能，或者不能保证线程之间的长期公平性，或者只能在高竞争的情况下同时保证性能核公平性。本文的研究首先针对紧凑放置不能保证长期公平性和平均放置性能较差的问题对其分别做了改进，对应得到以下两种新策略，加强的平均放置（restricted even）和有轮换的紧凑放置（compact with shift）
\begin{itemize}
\item 加强的平均放置。为了尽可能地保证平均放置的性能，我们限制该策略所能是使用地NUMA节点数为能满足需要地最少地节点数，而不是全部可用地节点数。相比原有的平均放置策略，新的策略在保证长期公平性地同时尽可能地保存局部性是层级锁能尽可能地挖掘局部性从而保证高性能，然而相比紧凑放置，新的策略在某些情况（竞争强度不足）下还是会有相当的性能损失。
\item 有轮换地紧凑放置。我们发现紧凑放置之后每个线程的吞吐率是由其所运行的位置决定的，所以在紧凑放置地基础上，引入了轮换（shift）机制，即通过定期地交换线程的位置来抹平线程的吞吐率之间的差异从而保证长期公平性。在有轮换的紧凑放置策略中，轮换的频率决定了最终的长期公平性的好坏。
\end{itemize}

基于上述两种改进后的策略我们提出了竞争感知地混合放置框架（contention-aware hybrid）。相比现有的单一固定的线程放置策略，该框架主要有以下几个特征：
\begin{itemize}
\item 竞争感知，该框架通过取样检测锁事件来评估当前地竞争状况，锁事件是每个线程与锁相关地操作（请求锁，拿锁，放锁）。
\item 混合，该框架可以被看作是有轮换的紧凑放置和加强的平均放置的混合体，在竞争强度足够的情况下应用加强的混合放置否则应用有轮换的紧凑放置策略，从而用最小的代价同时保证层级锁的性能和长期公平性。
\item 动态，该框架按照应用中层级锁的竞争状况动态地应用合适地线程放置策略。
\end{itemize}

在特定地应用中特定的竞争状况下，为了确定一个最合适线程放置策略，我们从Malthusian锁中引入了饱和点（saturation point）的概念。饱和点时能使保证某个线程放锁时总有至少一个其余线程在等锁的最小线程数。我们的线程放置框架偏向于应用加强的平均放置策略，因为相比有轮换的紧凑放置策略它没有课外的线程迁移开销。针对某个特定的竞争状况，如果采用加强的平均放置策略后，每个NUMA节点上的线程数大于等于饱和点就应用加强的平均放置策略，否则应用有轮换的紧凑放置策略。
\subsection{结构安排}
本文共分为五个章节，具体如下：

第一章为绪论，主要概括介绍了本文的研究背景和意义。即NUMA架构带来的新的机遇和挑战，以及NUMA架构下现有层级锁中线程放置策略的优劣，进而引出本文研究的内容和意义。

第二章详细介绍和分析层级所中现有线程放置策略中存在的问题即背后的原因，由此得出新的线程放置策略需要遵守的原则及其面临的挑战。

第三章阐述本文研究的竞争感知的混合线程放置框架MSS的架构设计和实现。

第四章通过实验验证MSS的有效性。

第五章对全文总结。
\section{本章小结}
本章主要介绍了这篇文章的研究背景和研究内容。