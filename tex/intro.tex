%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter01.tex for SJTU Master Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{绪论}
\label{chap:intro}


\section{研究背景和意义}
近年来，NUMA(Non-Uniform Memory Access,非一致性内存访问)\cite{feliu2012understanding}\cite{dashti2013traffic}架构的服务器逐渐普及，它的出现解决了对称多处理器（symmetric multiprocessor architecture，SMP）架构在可扩展性方面的局限性\cite{pusukuri2014shuffling}，所以已经成为现代服务器架构设计中的一种趋势和规范\cite{kashyap2017scalable}\cite{chabbi2016contention}\cite{chabbi2017efficient}。良好的可扩展性使得单个NUMA架构的机器上可以轻易集成更多的计算核心，更大容量的物理内存和更大的内存访问带宽。NUMA架构中计算、存储等资源被组织成若干节点（node），每个节点包括若干计算核心，一块物理内存，一个或多个内存访问控制器（memory controller）和多层缓存，计算节点之间通过高速芯片间通信介质连接。在NUMA架构的机器中，某个计算核心访问其所在的计算节点的本地内存，尤其是本地共享缓存的速度通常是访问在其他计算节点上的内存或缓存的速度的数倍，也就是说NUMA架构的机器中内存访问存在非一致性时延。另外，在同一个计算节点内部，由于缓存的的分层设计，同一个计算核心访问本地计算节点的不同层次的缓存也会有显著的非一致性时延\cite{chabbi2015high}。

对于大型内存数据库(例如Microsoft SQL server）\cite{MICROSOFT-SQL}和处理引擎\cite{SAP}\cite{zaharia2010spark}（例如spark）等通过高并发来处理大规模海量数据的应用来说，随着数据规模的指数增长，必然需要进一步地扩展，通过更高程度的并发来满足需求。而NUMA架构提供的更多的核，更大的内存容量和更大的内存访问带宽使得这些应用可以生成更多的线程，并将这些线程分布到所有的NUMA计算核心上来尽可能地利用所有NUMA节点的计算和存储资源。另一方面，NUMA架构本身存在的内存访问的非一致性时延以及NUMA节点之间的有限的带宽资源对系统的线程调度和内存管理提出了新的挑战\cite{wang2012performance}\cite{boyd2008corey}。这些共享内存的应用中线程之间通常存在大量的共享数据，数据在内存及缓存中的存储位置和及访问该数据的线程的在机器上执行位置决定了数据访问的效率，因而对于系统的整体性能有很大影响。合理的内存管理和线程调度能够充分利用数据访问的局部性提高性能，而不合理的内存管理和线程调度策略可能会造成整体性能的严重损失。

通过挖掘应用的数据访问特征，比如线程线程和线程之间的数据共享范围和共享频率来建立线程之间的亲和性（thread affinity）及线程与数据之间的亲和性（data affinity）\cite{diener2014kmaf}\cite{azimi2009enhancing}\cite{tikir2008hardware}，然后将共享数据多共享频率高的线程对调度到相同的NUMA节点上，同时将其最常访问的数据也放置在该NUMA节点上，可以充分利用数据访问的局部性来减少数据拷贝，减少缓存更新、增加缓存的利用率和命中率，降低数据访问延迟，进而提高应用的整体性能\cite{chishti2005optimizing}。除了将数据迁移到经常访问其的NUMA节点(co-location)外，通过分析数据本身的特征，比如读写比、共享范围、访问来源（来自于哪个NUMA节点）等,并且考虑NUMA节点间高速通信介质的数据传输压力及NUMA节点上内存控制器访问压力等因素后，还可以通过其他的内存管理方式来提高系统性能\cite{dashti2013traffic}\cite{molka2011memory}，比如对于共享范围很大的只读数据或者读写比非常高的数据可以通过在NUMA节点之间复制（replication）该数据来减少跨节点的数据访问；对于访问来源非常分散的共享热点数据可以通过将数据交织（interleaving）分布到各个NUMA节点来分摊内存控制器的访问压力；对于某些应用可以将数据放置在第一次（first-touch）访问其的线程所在NUMA节点来利用局部性等。

在线程之间所有共享的数据中，有部分特殊数据不能被多个线程同时访问因而需要一种同步机制来防止其被同时访问更新，尽管近年来事务内存（transaction memory）开始流行，但是对于多数高并发的应用来说，在高度竞争的情况下锁依然是一种最基本最重要并且广泛使用的同步机制\cite{tallent2010analyzing}\cite{johnson2010decoupling}。NUMA架构的出现对于锁的性能影响主要有三个方面：1）锁本身及其保护的数据都是线程之间的共享数据，这部分数据在所有共享数据中占比通常很小，并且通常读写比很低，所以内存管理（迁移，复制，交织等）对其性能基本没有影响，而线程调度会影响对其性能仍有重要影响；2）线程之间对于锁及其保护的数据的在时间上是不共享的，而这部分数据的访问顺序是由线程的拿锁顺序决定大的，所以通过线程调度优化锁的性能还必须考虑锁本身的传递机制；3）（互斥）锁保护的数据只能在线程间串行访问，这使得锁很容易成为应用的性能瓶颈甚至导致应用崩溃\cite{boyd2012non}，NUMA因素的出现进一步加剧了这种瓶颈，也对锁的设计提出了新的挑战。

在传统的SMP架构中，基于队列的锁，例如CLH锁\cite{craig1993building}\cite{magnusson1994queue}\cite{scott2013shared}和MCS锁\cite{mellor1991algorithms}\cite{scott2013shared}，广泛应用在许多锁集中的高性能系统中\cite{dice2011flat}。这些基于队列的锁将所有等待访问关键区域的线程排成先进先出（FIFO，first in first out）的队列，每个线程通过在队列中各自对应的内存位置上自旋来等待进入关键区域。相比所有线程在同一个内存位置上自旋的spin lock， FIFO的队列保证了基于队列的锁的公平性；每个线程在各自的内存位置上自旋，分散了线程对锁变量的竞争，减少了锁传递时的缓存更新，从而提能提供更好的性能和可扩展性。然而在NUMA架构中，这些基于队列的锁的性能显著下降，这主要是由NUMA架构机器的物理架构决定的，由于传统的基于队列的锁不能感知NUMA架构硬件层面的访存的非一致特性，同时为了保持先来先服务的锁传递顺序，就会产生锁在NUMA节点之间的随意传递，而锁在NUMA节点之间的传递地时延通常是在同一个NUMA节点内传递时延的数倍，从而加长锁传递的时间和关键区域的执行时间，增加时延，减小吞吐率，使得性能显著下降。

传统锁在NUMA架构上性能衰退的主要原因是跨节点的锁传递代价远高于同一节点内的锁传递代价而传统锁不能感知到底层的NUMA因素。NUMA感知的层级锁在考虑NUMA因素的情况下通过本地偏好的锁传递规则减少了锁的跨节点传递，从而改善了锁在NUMA架构下的性能表现。本文在此基础上从线程调度/放置策略的角度对现有的基于队列的层级锁的性能和其他特性（长期公平性）进行优化，使其能够更好地适应诸如公有云等对于锁的性能，公平性，可扩展性等都有很高要求的应用场景。

NUMA架构是可预见的未来大型计算机硬件架构设计的大趋势，而随着医疗，交通，社交等领域产生的大数据的爆发式的增长，以及云计算等共享计算资源模式的快速发展，大型应用对于性能，可扩展性和公平性等方面的要求必然进一步提高。本文的研究使得基于队列的层级锁能够更好地适应未来软硬件的特性和需求变化，更好地服务于当下和未来相关领域的发展。总而言之，NUMA架构的出现解决了大型计算机硬件层面的扩展性问题，使得高性能共享内存应用能够进一步地扩展来满足日益增长的数据处理的需要；层级锁的出现改善了基于队列的锁在NUMA架构下存在的性能衰退问题，但是也带来了长期公平性不足的新问题；而本文的研究从线程调度/放置的角度进一步地优化现有的层级锁设计，使其在保持性能和可扩展性的前提下在一定程度上保证公平性。考虑到NUMA架构的机器的不断普及以及发展趋势和公有云等对公平性，性能和可扩展性都有很高要求的应用场景的不断增多，本文的研究将使得层级锁能够更好适应这些应用场景的需求，并且在可预见的未来有更大应用前景。
\section{国内外研究现状}
性能和公平性是任何锁的设计中都必须要考虑的两个重要标准\cite{chabbi2015high}。一般情况下，线程执行关键区域的时间非常短，甚至可能比其拿锁的时间还要短\cite{johnson2010decoupling}，所以锁传递的时延对于锁的性能尤其是在锁的竞争已经饱和的情况下的性能的影响非常大。而在NUMA架构下，访存的非一致性时延特征导致跨节点的锁传递和同一节点内的锁传递在时延方面存在数倍的差异，从而使得跨节点的锁传递比例成了影响锁性能的关键因素。针对NUMA架构下跨节点的锁传递带来的锁性能下降问题，现有的优化方案大多数本质上都是通过减少锁的跨节点传递来改善其性能的，具体分为以下四类，即委托执行，线程聚类，线程迁移，NUMA感知的层级锁。另外，应用程序在NUMA架构下的进一步扩展使得其对锁的竞争变得更加难以预测，过度的竞争反而会带来系统整体性能的下降，所以通过竞争控制也能改善NUMA架构下锁的性能。

\subsection{委托执行}
为了避免锁在NUMA节点之间传递的巨大开销，要执行关键区域的线程可以委托一个或几个专门的核代为执行\cite{oyama1999executing}\cite{lozi2012remote}\cite{fatourou2012revisiting}\cite{hendler2010flat}\cite{guiroux2016multicore}，从而完全避免锁的传递所造成的缓存数据的同步及由此带来的时延增加和吞吐率损失，因为锁及其保护的数据始终在对应核的缓存中。这种方案的代价是需要额外的线程间通信并且至少需要一个专用的核专门执行关键区域。RCL（remote core locking）\cite{lozi2012remote}就是委托执行的一种，RCL的作者观察到大多数多线程应用并不需要或者不能扩展到现代多核机器的所有核上，所以让某几个特定的核专门执行关键区域既利用了空余的核又能带来潜在的性能提升，要执行关键区域的线程不需要通过竞争锁来进入关键区域，而是通过优化后的远程过程调用委托特定核完成关键区域的执行从而完全避免锁及其保护的数据的传递。委托执行本质上是在迁移关键区域的执行，相比其他锁，它能在某些特定应用中防止高度竞争情况下应用性能的崩溃，但是它最大的缺陷是需要修改使用传统锁的历史遗留代码，原有代码中的关键区域需要额外的技术和时间被识别和修改之后才能利用委托执行的的高性能。

\subsection{线程聚类}
线程聚类是把同一个应用的线程或者竞争同一个锁的线程放置到同一个NUMA节点上\cite{tam2007thread}\cite{thekkath1994impact}\cite{xian2008contention}。这样做的好处是所有的共享数据都存在于本地内存或者缓存中，并且将锁的传递限制在同一个NUMA节点内部，避免了锁在NUMA节点之间传递的开销。该方案本质上是通过建立线程间的亲和性来挖掘和利用数据访问的局部性，所以也常被用在一般的共享数据中将有共享内存数据的线程放置在同一个计算节点上来最大化缓存的共享和复用。线程聚类能显著改善线程较少的小规模应用
的性能，但是对于具有大量线程的高并发应用程序而言，其所拥有的线程数通常远大于单个节点上的计算核心，按照线程聚类的方法所有线程都会被分到一个聚类中，因而会产生负载不均衡的问题，同时并行性也被牺牲了，除此以外也会带来拿锁者被抢占或者等待者被抢占等新问题，最终的结果可能得不偿失，所以线程聚类一般只适用于线程数量较少的小规模应用。

\subsection{线程迁移}
在系统运行的同时，将锁的等待者动态地调度到锁的持有者当前所在NUMA节点上，从而减少锁及关键区域的数据在NUMA节点之间的传递\cite{sridharan2006thread}\cite{thekkath1994impact}。这种方案主要基于以下观察，即锁集中的多线程应用的性能对于线程在NUMA节点之间的分布高度敏感但是操作系统的调度器感知不到锁在线程之间的竞争自然不能将锁的竞争因素加入到调度器的调度策略中，所以线程迁移可以看作是在考虑锁竞争因素的情况下对操作系统默认调度器调度策略的一种补充。shuffling\cite{pusukuri2014shuffling}是通过线程迁移来提高锁的性能的一种，它定期地将线程按照其“到达时间”（线程请求锁的时间）来排序；然后将“到达时间”接近的线程分到同一组中，每组的线程数量大致等于单个NUMA节点上的计算核心数；最后将分到同一组的线程迁移到同一个NUMA节点上去执行。因为连续请求锁的线程被分为同一组并且放到同一个节点上执行，所以锁在节点之间的迁移频率被显著降低；另外放置在每个计算节点上的线程数不超过该节点上的计算核心数又能避免负载不均衡及抢占等问题。线程迁移能够有效减少锁及关键区域的迁移，提高系统的整体性能，并且不改变原有锁的传递顺序，代价则是较为频繁大量的线程迁移及其带来的潜在缓存污染等问题。

\subsection{NUMA感知的层级锁}
层级锁利用多层的锁来对应下层的NUMA结构，将锁的竞争分割在不同的NUMA节点或者同一个NUMA节点内部不同的计算核心上，从而减少锁及关键区域数据在NUMA节点间的随意迁移频率\cite{dice2012lock}。与其他解决方案的主要不同之处在于层级锁是对锁的调度，所以会改变原有锁的传递顺序。层级锁本质上是通过牺牲短期公平性来换取减少锁的跨节点传递频率提高锁的吞吐率的。具体来说，在层级锁中，锁的持有者会优先将锁传递给当前节点上的最早的请求者而不是所有节点范围内的最早的请求者，只有当前节点上没有请求者时才会传给其他节点上的请求者。另外为了避免饥饿（starvation）及深度不公平等问题，层级锁中通常会设定一个上限（threshold）来限制其在同一个节点内的连续传递次数。

现有的层级锁设计方案包括lock cohorting\cite{dice2012lock}， HMCS锁\cite{chabbi2015high}，AHMCS锁\cite{chabbi2016contention}和HMCS-T\cite{chabbi2017efficient}等。lock cohorting的设计包括一个全局锁（global lock）和每个NUMA节点上的本地锁（local lock）。全局锁和本地锁都可以是任何传统的锁（MCS, CLH，门票锁，自旋锁等）。全局锁在所有节点之间共享，它的主要功能是将竞争分隔到各个节点之内。一个本地锁只在本地节点里边的线程之间共享并且用来同步本地节点内的线程。一个线程只有同时拿到全局锁和其所在节点的本地锁才可以访问关键区域，通常的拿锁顺序是先拿本地锁再拿全局锁。层级锁一般用在竞争线程多竞争激烈的场景中，所以大多数情况下同一个NUMA节点内的线程只需要有一个线程显式拿全局锁另一个线程显式放全局锁，其他线程直接继承全局锁。由于只有全局锁会在节点之间传递并且该传递频率因为竞争分割的关系会很低，所以锁的整体性能显著提高。

HMCS将lock cohorting的思想推广到了具有深层NUMA架构的机器中，从而使用三层甚至四层地MCS锁来潜在地发掘和利用各个NUMA层次的局部性获取更高的性能。HMCS适合竞争线程多竞争锁请求频繁的场景，但是竞争强度较小或者没有竞争的场景下，其多层的锁架构会带来较大的时延。AHMCS针对该问题使用多个互相正交的策略（事务性内存，竞争感知、动态适应的锁树等）来同时达到高竞争时的高吞吐和低竞争时的低时延。HMCS-T保持了HMCS的高性能，并且通过超时机制来使HMCS具备放弃竞争特性从而控制竞争者数量避免无意义的空转等待。由于基于队列的MCS锁相比自旋锁、门票锁等在高度竞争地场景下具有性能好，可扩展性好，并且保证公平性等优点，所有大多数层级锁中将MCS锁作为其各层的基本锁。上述层级锁具有不同的其他方面地特征和创新，但它们都是通过竞争分割降低锁的跨节点传递频率来提高锁的吞吐率的。

\subsection{竞争控制}
许多并行程序的线程之间的通信变化是不可预测的，这使得线程对于共享数据的竞争无法预测和控制，从而使得大多数情况下表现良好的锁可能因为线程对共享数据的竞争的突然加剧而性能急剧下降甚至崩溃\cite{johnson2010decoupling}\cite{boyd2012non}。在NUMA架构下，如前所述，硬件的扩展使得软件应用规模进一步加大，从而使得共享数据的竞争更加不可预测和控制，也进一步加大了应用性能下降和崩溃的风险，所以通过控制线程对于共享数据的竞争也可以改善NUMA架构下锁的性能。

F.Ryan Johnson\cite{johnson2010decoupling}认为通过自旋（spinning）能够最大化锁的性能但是会白白浪费计算资源，而基于阻塞（blocking）的方式节省了计算资源但是可能会加长关键区域的执行时间，同时在高度竞争或者负载变化的情况下，操作系统的调度造成的线程被抢占进一步加剧了上述两种竞争控制策略的缺陷。作者观察到竞争控制与线程调度或者负载管理带来的问题之间是正交的，所以将两者解耦能够更有效的解决两者带来的问题，基于此提出了一种与竞争大小相解耦的的负载控制机制来控制活跃线程数，从而能结合利用spinning的高效性和blocking大的健壮性。类似的，CST锁\cite{kashyap2017scalable}中作者认为简单的spin，block或者spin-then-block竞争控制机制都不能解决NUMA架构下锁存在的扩展性问题，因为不管哪种机制都会受到操作系统调度器的调度决策的影响，所以提出在锁传递的时候在尽可能地保证先来先服务（first-in first-out）的顺序下应该尽可能地将锁传给处于spinning状态的竞争者，从而尽可能地避免因为线程调度而加长关键区域的执行时间。

AHMCS\cite{chabbi2016contention}锁中，作者认为NUMA架构下可扩展性和性能都很好地HMCS\cite{chabbi2015high}锁不能适应竞争和负载多变的环境。HMCS锁在高竞争的情况下能够利用局部性感知提供高吞吐率，但是在竞争很小地情况下局部性感知本身没有必要而且为了进行局部性感知会造成不必要的额外时延，在此基础上作者认为局部性感知的锁应该是竞争感知的，并且提出了可以动态适应竞争变化，动态改变锁的层数的AHMCS锁，从而使其能够在高度竞争的情况下保持高吞吐率的同时在竞争强度不高时也能保证低时延。

Multhusian锁\cite{dice2017malthusian}的作者认为现代大型应用程序大多数使用了过多的线程（overthreaded），大部分这类程序中由于锁的高度竞争，过多的线程非但没有提高应用的性能，反而可能因为扩展性崩溃（scalability collapse）而造成性能衰退。作者通过实验说明了大多数应用中，随着线程数的增多，在锁饱和前性能就开始衰退了，所以使锁饱和的线程数可以用来作为竞争控制的目标。为了将线程数控制在饱和点附近，作者对MCS锁的传递机制进行了修改，借用了内存管理中的thrashing机制\cite{denning1980working}将所有线程分为了活跃态（可以请求锁）和抑制态（不能请求锁）两个集合，其中处于活跃态的线程数大约等于锁的饱和点大小，从而有效控制了竞争线程数进而保证性能不会下降太多。该方案事实上通过牺牲MCS锁的短期公平性来放置性能下降，为了保证长期公平性，作者使用了shift机制来在两个集合之中循环移动线程。

\section{研究内容和结构安排}
本文的研究在基于队列的层级锁基础上，针对现有层级锁中的简单单一的线程放置策略不能在锁的竞争复杂多变的情况下同时保证其性能和长期公平性的缺陷，提出了一种新的竞争感知的混合线程放置框架，使得基于队列的层级锁能够在竞争状况变化的情况下以尽可能小的代价同时达到高性能和保证长期公平性。


\subsection{竞争感知的混合调度框架}
性能和公平性是任何锁设计中最重要的两个指标，而目前的层级锁设计及其线程放置策略或者不能保证最佳的性能，或者不能保证线程之间的长期公平性，或者只能在高竞争的情况下同时保证性能和公平性。究其原因主要有两点：1）现有部分线程放置策略没有考虑对性能和长期公平性都有很高要求的应用场景；2）简单单一的线程放置策略难以满足复杂多变的应用竞争状况。对于公有云等很多应用场景来说，为了给用户提供按需付费的服务并且高效地利用计算、存储等资源，性能和公平性对于其的成功都是至关重要的\cite{rao2014towards}；另外，很多大型应用中线程之间对于共享资源的竞争是不可预测和控制的，通常情况下竞争很小的一块共享数据可能会突然变得高度竞争，比如搜索引擎中突然出现的热门事件的搜索\cite{chabbi2016contention}。所以为了适应这些复杂应用场景的需求，现有的基于队列的层级锁的线程放置策略必须要先解决上述两个缺陷/挑战。

基于此，本文的研究首先针对紧凑放置不能保证长期公平性和平均放置性能较差的问题对其分别做了改进，对应得到以下两种新策略，加强的平均放置（Enhanced Even，EE）和有轮换的紧凑放置（Compact With Shift，CWS）
\begin{itemize}
\item 加强的平均放置。为了尽可能地保证平均放置的性能，我们限制该策略所能使用的NUMA节点数为能满足需要的最少的节点数，而不是全部可用的节点数。相比原有的平均放置策略，新的策略在保证长期公平性的同时尽可能地保存局部性使得层级锁能尽可能地挖掘局部性从而保证高性能，然而相比紧凑放置，新的策略在某些情况（竞争强度不足）下还是会有相当的性能损失。
\item 有轮换的紧凑放置。我们发现紧凑放置之后每个线程的吞吐率是由其所运行的位置决定的，所以在紧凑放置的基础上，引入了轮换（shift）机制，即通过定期地交换线程的位置来抹平线程的吞吐率之间的差异从而保证长期公平性。在有轮换的紧凑放置策略中，轮换的频率决定了最终的长期公平性的好坏。
\end{itemize}
基于上述两种改进后的策略及应用程序竞争状况复杂多变的特征，我们提出了竞争感知地混合线程放置框架（Contention-Aware Hybrid Thread Placement Framework）CAH。相比现有的简单单一的线程放置策略，CAH主要有以下几个特征：
\begin{itemize}
\item 竞争感知，该框架通过取样检测锁事件来评估当前的竞争状况，从而能够适应复杂多变的程序竞争状况。其中锁事件是每个线程与锁相关的操作（请求锁，拿锁，放锁）。
\item 混合，该框架可以被看作是有轮换的紧凑放置和加强的平均放置的混合体，在竞争强度足够的情况下应用加强的平均放置否则应用有轮换的紧凑放置策略，最终的目的是用最小的代价同时保证层级锁的性能和长期公平性。
\item 动态，该框架按照应用中层级锁的复杂多变的竞争状况动态地应用合适的线程放置策略。
\end{itemize}

在特定应用中特定的竞争状况下，为了确定一个最合适线程放置策略，我们从Malthusian锁中引入了饱和点（saturation point）的概念。饱和点是能保证某个线程放锁时总有至少一个其余线程在等锁的最小线程数。我们的线程放置框架偏向于应用加强的平均放置策略，因为相比有轮换的紧凑放置策略它没有额外的线程迁移开销。针对某个特定的竞争状况，如果采用加强的平均放置策略后，每个NUMA节点上的线程数大于饱和点，则能在保证长期公平性的情况下获取高性能，所以应用加强的平均放置策略，否则应用有轮换的紧凑放置策略。
\subsection{结构安排}
本文共分为五个章节，具体如下：

第一章为绪论，主要概括介绍了本文的研究背景、意义及本文的研究内容。本文大的研究大背景主要是NUMA架构的扩展性和访存的非一致性带来的新的机遇和挑战，尤其是NUMA架构给现有锁设计带来的挑战。本文的研究基于NUMA感知的基于队列的层级锁，对基于队列的层级锁中现有线程放置策略进行了改进并提出了一种竞争感知的混合线程放置框架使其能够在应用中锁竞争复杂多变的场景下同时保证性能和长期公平性。

第二章介绍了相关研究和技术。包括NUMA架构的特征及相关优化技术，MCS锁、C-MCS锁的算法及其相比其他锁的优缺点，基于队列的层级锁中现有的线程调度/放置策略及其适应场景等。

第三章在对层级锁的锁传递机制及现有线程放置策略做了详细分析，并配合相关的实验验证后，发现现有的线程放置策略的设计初衷对于保证锁的性能或长期公平性是充分而不必要的，在此基础上分别针对现有的两种线程放置策略提出了相应的改进思路，并在这两种改进思路的基础上提出了一套在保证锁的性能和长期公平性的前提下额外开销尽可能小的综合线程放置方案，即竞争感知的混合线程放置框架CAH。

第四章详细阐述了本文研究的竞争感知的混合线程放置框架CAH的架构设计和实现。其中CAH的设计方面包括基本的设计思路即CAH如何解决现有线程放置方案存在的缺陷、CAH的架构和核心算法。CAH的实现主要包含了线程迁移，策略切换等的实现细节。

第五章通过在microbenchmark stress\_one和实际应用memcached上的实验说明了本文的两个改进线程放置策略及CAH整体相对层级锁中原有线程放置策略的有效性。

第六章对全文进行了总结和展望。
\section{本章小结}
本章首先介绍了NUMA架构的基本特征及其对于多线程高性能软件设计尤其是锁带来的机遇和挑战，然后介绍现有研究针对传统锁在NUMA架构下性能下降所做的改进（主要是基于队列的层级锁），接着分析了现有层级锁中线程放置策略存在的优缺点，最后基于现有线程放置策略相应提出了本文的研究内容：针对基于队列的层级锁的竞争感知的混合线程放置框架。