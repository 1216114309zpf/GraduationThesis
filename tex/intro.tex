%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter01.tex for SJTU Master Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{绪论}
\label{chap:intro}


\section{研究背景和意义}
近年来，NUMA(Non-Uniform Memory Access,非一致性内存访问)\cite{feliu2012understanding}\cite{dashti2013traffic}架构的服务器逐渐普及，它的出现解决了对称多处理器（symmetric multiprocessor architecture，SMP）架构在可扩展性方面的局限性\cite{pusukuri2014shuffling}，所以已经成为现代服务器架构设计中的一种趋势和规范\cite{kashyap2017scalable}\cite{chabbi2016contention}\cite{chabbi2017efficient}。良好的可扩展性使得单个NUMA架构的机器上可以轻易集成更多的计算核心，更大容量的物理内存和更大的内存访问带宽，使得应用程序可以更好利用线程级别的并行性。计算核心通常被组织成一个计算节点（node）集合，每个计算节点包括若干计算核心，一块物理内存，一个内存访问控制器（memory controller）和多层缓存，计算节点之间通过高速芯片间通信介质连接。在这种架构的机器中，某个计算核心访问其所在的计算节点的本地内存，尤其是本地共享缓存的速度通常是访问在其他计算节点上的内存或缓存的速度的数倍，也就是说NUMA结构的机器中内存访问存在非一致性时延。另外，在同一个计算节点内部，由于缓存的的分层设计，同一个计算核心访问本地计算节点的不同层次的缓存也会有显著的非一致性时延\cite{chabbi2015high}。

对于大型内存数据库(例如Microsoft SQL server）\cite{MICROSOFT-SQL}和处理引擎\cite{SAP}\cite{zaharia2010spark}（例如spark）等通过高并发来处理大规模海量数据的应用来说，随着数据规模的指数增长，必然需要进一步地扩展，通过更高程度的并发来满足需求。而NUMA架构提供的更多的核，更大的内存容量和更大的内存访问带宽使得这些应用可以生成更多的线程，并将这些线程分布到所有的NUMA计算核心上来尽可能地利用所有NUMA节点的计算和存储资源。另一方面，NUMA架构本身存在的内存访问的非一致性时延以及NUMA节点之间的有限的带宽资源使得系统性能存在很大的不确定性，也对系统的线程调度和内存管理提出了新的挑战\cite{wang2012performance}\cite{boyd2008corey}。这些共享内存的应用中线程之间通常存在大量的共享数据，数据在内存及缓存中的存储位置和及访问该数据的线程的在机器上执行位置决定了数据访问的时延和最大带宽，因而对于系统的整体性能有很大影响。合理的内存管理和线程调度能够充分利用数据访问的局部性提高性能，而不合适的内存管理和线程调度策略可能会造成整体性能的严重损失。

通过挖掘应用的数据访问特征，比如线程线程和线程之间的数据共享范围和共享频率来建立线程之间的亲和性（thread affinity）及线程与数据之间的亲和性（data affinity）\cite{diener2014kmaf}\cite{azimi2009enhancing}\cite{tikir2008hardware}，然后将共享数据多共享频率高的线程对调度到相同的NUMA节点上，同时将其最常访问的数据也放置在该NUMA节点上，可以充分利用数据访问的局部性来减少数据拷贝，增加缓存的利用率和命中率，降低数据访问延迟，减少NUMA节点间通信介质上的缓存一致数据流，进而提高应用的整体性能\cite{chishti2005optimizing}。除了将数据迁移到经常访问其的NUMA节点(co-location)外，通过分析数据本身的特征，比如读写比、共享范围、访问来源（来自于哪个NUM）等,并且考虑NUMA节点间高速通信介质的数据传输压力及NUMA节点上内存控制器访问压力等因素后，还可以通过其他的内存管理方式来提高系统性能\cite{dashti2013traffic}\cite{molka2011memory}，比如对于共享范围很大的只读数据或者读写比非常高的数据可以通过在NUMA节点之间复制（replication）该数据来减小节点间的通信压力；对于访问来源非常分散的共享数据可以通过将数据交织（interleaving）分布到各个NUMA节点来分摊内存控制器的访问压力；对于某些应用可以将数据放置在第一次访（first-touch）问其的线程所在NUMA节点来利用局部性等。

在线程之间所有共享的数据中，有部分特殊数据不能被多个线程同时访问并通常需要一种同步机制来防止其被同时访问更新，尽管近年来事务内存（transaction memory）开始流行，但是对于多数高并发的应用来说，在高度竞争的情况下锁依然是一种最基本最重要并且广泛使用的同步机制\cite{tallent2010analyzing}\cite{johnson2010decoupling}。NUMA架构的出现对于锁的性能影响主要有三个方面：1）锁本身及其保护的数据都是线程之间的共享数据，这部分数据在所有数据中共享数据中占比通常很小，并且读写比很低，所以内存管理（迁移，复制，交织等）对其性能基本没有影响，而线程调度会影响对其性能仍有重要影响；2）线程之间对于锁及其保护的数据的在时间上时不共享的，而这部分数据的访问顺序是由线程的拿锁顺序决定大的，所以通过线程调度优化锁的性能还必须考虑锁本身的传递机制；3）（互斥）锁保护的数据只能在线程间串行访问，这使得锁很容易成为应用的性能瓶颈甚至导致应用崩溃，NUMA因素的出现进一步加剧了这种瓶颈，也对锁的设计提出了新的挑战。

在传统地SMP架构中，基于队列地锁，例如CLH\cite{craig1993building}\cite{magnusson1994queue}\cite{scott2013shared}和MCS锁\cite{mellor1991algorithms}\cite{scott2013shared}，一直是许多锁集中的高性能系统地不二之选。这些基于队列的锁被选择的主要原因是，他们将所有等待访问关键区域的线程排成先进先出的队列，每个线程在被分隔开的内存区域等待锁，从而减少了总的用于维持缓存一致性的数据流，提高了系统的总体性能和可扩展性。然而在NUMA架构中，这些基于队列的锁的性能显著下降，这主要是由NUMA架构机器的物理架构决定的。由于传统的基于队列的锁不知道NUMA架构硬件层面的内存及缓存的非一致特性，为了保持先来先服务的锁传递顺序，就会产生锁在各个NUMA计算节点之间的随意传递，而锁及其保护的数据在NUMA节点之间的传递需要时间通常会是在同一个NUMA节点内传递时间的数倍，从而加长锁传递的时间和关键区域的执行时间，增加时延，减小吞吐率，使得性能会有显著下降。

传统锁在NUMA架构上性能衰退的主要原因是锁在NUMA节点之间的传递代价较大，所以目前针对该问题的解决方案的目标都是减小锁在NUMA节点之间的传递频率，现有的解决方案主要有两类：通过线程调度和通过改变锁本身的传递机制。本文主要从线程/调度放置策略的角度对现有的基于改变锁的传递规则的方案（层级锁）进行的性能和其他特性（长期公平性）进行优化，使其能够更好地适应诸如公有云等对于锁的性能，公平性，可扩展性等都有很高要求地应用场景。

NUMA架构是可预见的未来大型计算机硬件架构设计的大趋势，而随着医疗，交通，社交等领域产生的大数据的爆发式的增长，以及云计算等共享计算资源模式的快速发展，大型应用对于性能，可扩展性和公平性等方面的要求必然进步提高。本文的研究使得层级锁能够更好地适应未来软硬件的特性和需求变化，更好地服务于当下和未来相关领域的发展。总而言之，NUMA架构的出现解决了大型计算机硬件层面的扩展性问题，使得高性能共享内存应用能够进一步地扩展来满足日益增长地数据处理地需要；层级锁的出现改善了应用中使用地传统锁在NUMA架构下存在的性能不足问题，但是也带来了公平性不足的新问题；而本文的研究从线程调度/放置的角度进一步的优化现有的层级锁设计，使其在保持性能和可扩展性的前提下在一定程度上保证公平性。考虑到NUMA架构的机器的不断普及以及发展趋势和公有云等对公平性，性能和可扩展性都有很高要求的应用场景的不断增多，本文的研究将使得层级锁能够更好适应这些应用场景地需求，并且在可预见地未来有更大应用前景。
\section{国内外研究现状6.5}
锁本质上是一种软件实现的同步机制，其在硬件层面主要基于缓存一致性协议，所以本节先简述锁实现中硬件方面的主要代价\cite{david2013everything}，然后基于缓存一致性协议介绍几种主要传统锁的优劣和演化，最后详细介绍包括层级锁在内的现有针对NUMA架构的锁优化方案。
\subsection{缓存一致性}
缓存一致性（cache coherence）是一种保持缓存中数据一致性的硬件协议，该协议通常实了现两个基本的操作：load和store，除此以外通常也会提供更复杂的操作像原子操作（atomic operation）， 例如compareand-swap,
fetch-and-increment等。在NUMA架构上，为了保持缓存一致性的而产生load或store的时延与两个相关缓存线是否跨NUMA节点有很大关系，跨节点的通信时延通常要比节点内的通信时延长2到7.5倍\cite{david2013everything}，这是传统锁在NUMA架构下性能衰退的根本原因。原子操作操作是一个或一系列的不可被中断的操作，是实现互斥锁保证互斥的基石，它通常是重量级的指令所以其代价比一般的读写操作高昂得多。

当前的大多数处理器使用MESI\cite{papamarcos1984low}缓存一致性协议或者是它的变体，MESI定义四种缓存行（cache line）状态，即modified（内存中对应的数据已经被更新，并且没有其他cache缓存该数据），exclusive（该数据与内存中的数据一致并且没有其他cache缓存该数据），shared（该数据与内存中的数据一致并且其他cache有可能缓存了该数据）和invalid（数据非法），在缓存行的状态转移过程中，处理器一般通过snooping或者使用directory来实现缓存行的一致性。使用snooping时，每个缓存都在总线上监听所有相关数据流来保持其存储数据的一致性，其不需要额外的directory，但是扩展性较差，比较适合机器规模较小的情况；一个directory保存有哪个缓存行缓存有哪个内存位置的大致或者精确信息，每个保持缓存一致性的操作都需要先查询directory，这种实现方式产生的缓存一致性数据流少，可扩展性较好，适合机器规模较大的情况。上述两种缓存一致性协议的实现方式所产生的时延大小，带宽占用和可扩展性都有很大差别，在有些大规模的NUMA架构下也采用混合的实现方式，即在NUMA节点内部采用snooping而在NUMA节点之间采用directory机制。
\subsection{非NUMA架构下锁的演化}
\subsubsection{自旋锁}
自旋锁（spin lock）\cite{anderson1990performance}\cite{mellor1991algorithms}\cite{scott2013shared}是最简单的锁，在自旋锁中，所有竞争锁的线程共享同一个锁变量并且通过原子操作在该变量上自旋直到拿到锁。自旋锁合竞争线程较少竞争不太激烈的场景下能够避免复杂锁机制带来的高时延，但是在竞争线程较多竞争激烈的环境下存在下述三个问题
\begin{itemize}
\item 不能保证公平性，线程的拿锁顺序与其请求锁的顺序没有关系；
\item 性能较差，因为不停的自旋操作是以大量代价高昂的原子操作为代价的;
\item 可扩展性很差，因为所有线程共享同一个锁变量，每次锁传递都会带来大量的缓存更新，而缓存更新的时延通常O(N)的，其中N是共享锁变量的竞争者数。
\end{itemize}

\subsubsection{门票锁}
门票锁（ticket lock）\cite{mellor1991algorithms}\cite{dice2011brief}通过分发“门票”来控制线程按照其请求锁的顺序进入关键区域。在门票锁中，请求锁的线程先递增当前的票面值得到自己的门票号码，然后等待服务号码（serving number）和自己的门票号码一致时进入关键区域，并且自退出关键区域后递增服务号码。相比自旋锁，门票锁通过单调增加的门票号保证了先来先服务的公平性，此外也提高了性能因为在门票锁中只有拿门票的时候会用到原子操作。但是和自旋锁一样，门票锁的可扩展性很差，因为服务号码是在所有竞争锁的线程之间共享的，每次更当前的服务号码都会造成O(N)的缓存更新。

\subsubsection{队列锁}
基于队列的锁，例如MCS锁\cite{mellor1991algorithms}\cite{scott2013shared}，CLH锁\cite{craig1993building}\cite{magnusson1994queue}\cite{scott2013shared}在保持门票锁的公平性和性能的同时解决了上述两种锁扩展性不足的问题。在这些锁中，为了拿到锁，每个线程在当前的等待队列队尾加一个条目，然后在该条目上自旋直到前一个竞争者将锁传递过来。和门票锁一样，只有在入队的时候需要进行原子操作所以性能较好，而队列的存在和维护保证了公平性。相比门票锁，基于队列的锁中没有全局共享的锁变量，只有队列中的两个相邻的线程之间会缓存对方的自旋地址，每个竞争者在自己的条目上自旋，锁传递锁带来的缓存更新是O（1）的，与竞争者数量无关，所以保极大地提高了可扩展性。

\subsection{NUMA架构下的锁优化方案}
一般情况下，线程执行关键区域的时间非常短，可能比其拿锁的时间还要短\cite{johnson2010decoupling}，所以尽可能地降低线程大之间地锁传递时间对于保障锁的性能尤其是在锁的竞争已经饱和地情况下的性能非常关键，而在NUMA架构下，跨节点锁传递与节点内锁传递耗时之间地巨大差异使得挖掘和利用线程之间关键共享数据访问地局部性对于提高锁的性能更为重要。在NUMA架构下传统锁及关键区域在计算节点之间随意迁移导致了大量的跨节点缓存一致性操作，进而导致锁性能严重下降。对于上述问题目前已有多种改善方案，除了事务性内存等无锁解决方案以外，现有其它解决方案大致可以分为以下四类，即委托执行，线程聚类，线程迁移，竞争控制，NUMA感知的层级锁。
\subsubsection{委托执行}
为了避免锁在NUMA节点之间传递的巨大开销，要执行关键区域的线程可以委托一个或几个专门的核代为执行\cite{oyama1999executing}\cite{lozi2012remote}\cite{fatourou2012revisiting}\cite{hendler2010flat}\cite{guiroux2016multicore}，从而完全避免锁的传递所造成的缓存数据的同步及由此带来的时延和吞吐率损失，因为锁及其保护的数据始终在对应核的缓存中。这种方案的代价是需要额外的线程间通信并且至少需要一个线程专门执行关键区域。RCL（remote core locking）\cite{lozi2012remote}就是委托执行的一种，RCL的作者观察到大多数多线程应用并不需要或者不能扩展到现代多核机器的所有核上，所以让某几个特定的核专门执行关键区域及利用了空余的核由可能会带来潜在的性能提升，要执行关键区域的线程不需要通过竞争锁来进入关键区域，而是通过优化后的远程过程调用委托特定核完成关键区域的执行从而来完全避免锁及其保护的数据的传递。委托执行本质上是在迁移关键区域的执行，相比传统锁，它能在某些特定应用中限制高度竞争情况下应用性能的崩溃，但是它最大的缺陷是需要修改使用传统锁的历史遗留代码，原有代码中的关键区域需要额外的技术和时间被识别和修改之后才能利用委托执行的的高性能。
\subsubsection{线程聚类}
线程聚类是把同一个应用的线程或者竞争同一个锁的线程放置到同一个NUMA节点上\cite{tam2007thread}\cite{thekkath1994impact}\cite{xian2008contention}。这样做的好处是所有的数据都存在于本地内存或者缓存中，并且将锁的传递限制在同一个NUMA节点内部，避免锁在NUMA节点之间传递的开销。该方案本质山是通过建立线程间的亲和性来挖掘和利用数据访问的局部性，所以也常被用在一般的共享数据中将有共享内存数据的线程放置在同一个计算节点上来最大化缓存的共享和复用，由于一般的共享数据并不像锁一样在所有线程间共享，所以这种情况下还涉及线程间共享数据及其共享范围的检测。线程聚类能显著改善线程较少的小规模应用的性能，但是对于具有大量线程的高并发应用程序而言，其所拥有的线程数通常远大于单核计算节点上上的计算核心，按照线程聚类的方法所有线程都会被分到一个聚类中，因而会产生负载不均衡的问题，同时并行性也被牺牲了，除此以外也会带来拿锁者被抢占或者等待者被抢占等新问题，最终的结果可能得不偿失，所以线程聚类一般只适用于线程数量较少的小规模应用。
\subsubsection{线程迁移}
在系统运行的同时，将锁的等待者动态地调度到锁的持有者当前所在NUMA节点上，从而避免锁及关键区域的数据在NUMA节点之间的传递\cite{sridharan2006thread}\cite{thekkath1994impact}。这种方案主要基于以下观察，即锁集中的多线程应用的性能对于线程在NUMA节点之间的分布高度敏感但是操作系统的调度器感知不到锁在线程之间的竞争自然不能将锁的竞争因素加入到调度器地调度策略中，所以线程迁移可以看作是在考虑锁竞争因素的情况下对操作系统默认调度器调度策略的一种补充。shuffling\cite{pusukuri2014shuffling}是通过线程迁移来提高锁的性能的一种，它定期地将线程按照其“到达时间”（线程请求锁的时间）来排序；然后将”到达时间“接近的线程分到同一组中，每组的线程数量大致等于单个NUMA节点上的计算核心数；最后将分到同一组的线程迁移到同一个NUMA节点上去执行。因为连续请求锁的线程被分为同一组并且放到同一个节点上执行，所以锁在节点之间的迁移频率被显著降低；另外放置在每个计算节点上的线程数不超过该节点上的计算核心数又能避免负载不均衡及抢占等问题。线程迁移能够有效地减小锁及关键区域的迁移频率，提高系统的整体性能，并且不改变原有锁的传递顺序，代价则是较为频繁大量的线程迁移及其带来的潜在缓存污染等问题。
\subsubsection{竞争控制}
许多并行程序的线程之间的通信变化是不可预测的，这使得线程对于共享数据的竞争无法预测和控制，从而使得大多数情况下表现良好的锁可能因为线程对共享数据的竞争的突然加剧而性能急剧下降甚至崩溃\cite{johnson2010decoupling}\cite{boyd2012non}。在NUMA架构下，如前所述，硬件的扩展使得软件应用规模进一步加大，从而使得共享数据的竞争更加不可预测和控制，也进一步加大了应用性能下降和崩溃的风险，所以通过控制线程对于共享数据的竞争也可以改善NUMA架构下锁的性能。

F.Ryan Johnson\cite{johnson2010decoupling}认为通过自旋（spinning）能够最大化锁的性能但是会白白浪费计算资源，而基于阻塞（blocking）的方式节省了计算资源但是可能会加长关键区域的执行时间，同时在高度竞争或者负载变化的情况下，操作系统的调度造成的线程被抢占进一步加剧了上述两种竞争控制策略的缺陷。作者观察到竞争控制与线程调度或者负载管理带来的问题之间是正交的，所以将两者解耦能够更有效的解决两者带来的问题，基于此提出了一种与竞争大小相解耦的的负载控制机制来控制活跃线程数，从而能结合利用spinning的高效性和blocking大的健壮性。类似的，CST锁\cite{kashyap2017scalable}中作者认为简单的spin，block或者spin-then-block竞争控制机制都不能解决NUMA架构下锁存在的扩展性问题，因为不管哪种机制都会收到操作系统调度器的调度决策的影响，所以提出在锁传递的时候在尽可能地保证先来先服务（first-in first-out）地顺序下应该尽可能地将锁传给处于spinning状态地竞争者，从而尽可能地避免因为线程调度而加长关键区域地执行时间。

AHMCS\cite{chabbi2016contention}锁中，作者认为NUMA架构下可扩展性和性能都很好地HMCS\cite{chabbi2015high}锁不能适应竞争和负载多变地环境。HMCS能在高竞争的情况下能够利用局部性感知提供高吞吐率，但是在竞争很小地情况下局部性感知本身没有必要而且为了进行局部性感知会造成不必要地额外时延，在此基础上作者认为局部性感知的锁应该是竞争感知的，并且提出了可以动态适应竞争变化，动态改变锁的层数的AHMCS锁，从而使其能够在高度竞争的情况下保持高吞吐率的同时在竞争强度不高时也能保证低时延。

Multhusian锁\cite{dice2017malthusian}的作者认为现代大型应用程序大多数使用了过多的线程（overthreaded），大部分这类程序中由于锁的高度竞争，过多的线程非但没有提高应用的性能，反而可能因为扩展性崩溃（scalability collapse）而造成性能衰退。作者通过实验说明了大都数应用中，随着线程数的增多，在锁饱和前性能就开始衰退了，所以是锁饱和的线程数可以用来作为竞争控制的目标。为了将线程数控制在饱和点附近，作者对MCS锁的传递机制进行了修改，借用了内存管理中的thrashing机制\cite{denning1980working}将所有线程分为了活跃态（可以请求锁）和抑制态（不能请求锁）两个集合，其中处于活跃态的线程数大约等于锁的饱和点大小，从而有效控制了竞争线程数进而保证性能不会下降太多。该方案事实上通过牺牲MCS锁的短期公平性来放置性能下降，为了保证长期公平性，作者使用了shift机制来在两个集合之中循环移动线程。


\subsubsection{NUMA感知的层级锁}
层级锁利用多层的锁来对应下层的NUMA结构，将锁的竞争分割在不同的NUMA节点或者同一个NUMA节点内部不同的计算核心上，从而减少锁及关键区域数据在NUMA节点间的随意迁移频率\cite{dice2012lock}。与其他解决方案的主要不同之处在于层级锁是对锁的调度，所以会改变原有锁的传递顺序。层级锁本质上是通过牺牲短期公平性来换取减少锁的跨节点传递频率提高锁的吞吐率的。具体来说，在层级锁中，锁的持有者会优先将锁传递给当前节点上的最早的请求者而不是所有节点范围内的最早的请求者，只有当前节点上没有请求者时才会传给其他节点上的请求者。另外为了避免饥饿（starvation）及深度不公平等问题，层级锁中通常会设定一个上限（threshold）来限制其在同一个节点内的连续传递次数。

现有的层级锁设计方案包括lock cohorting\cite{dice2012lock}， HMCS锁\cite{chabbi2015high}，AHMCS锁\cite{chabbi2016contention}和HMCS-T\cite{chabbi2017efficient}等。lock cohorting的设计基于一个全局锁（global lock）和每个NUMA节点上的本地锁（local lock）。全局锁和本地锁都可以任何传统的锁（MCS, CLH，门票锁，自旋锁等）。全局锁在所有节点之间共享，它的主要功能时将竞争分隔到各个节点之内。一个本地锁只在本地节点里边的线程之间共享并且用来同步本地节点内的线程。一个线程只有同时拿到全局锁和其所在节点的本地锁才可以访问关键区域。通常的拿锁顺序是先拿本地锁再拿全局锁，而放锁的顺序正好相反。层级锁一般用在竞争线程多竞争激烈的场景中，所以大多数情况下同一个NUMA节点内地线程只需要有一个线程显式拿全局锁另一个线程显式放全局锁，其他线程直接继承全局锁。由于只有全局锁会在节点之间传递并且该传递频率因为竞争分割的关系会很低，所以锁的整体性能显著提高。

HMCS将lock cohorting的思想推广到了具有深层NUMA架构的机器中，从而使用三层甚至四层地MCS锁来潜在地发掘和利用各个NUMA层次地局部性获取更高地性能。HMCS适合竞争线程多竞争锁请求频繁的高竞争的场景，但是竞争强度较小或者没有竞争地情况下，其多层地锁架构会带来较大地时延。AHMCS针对该问题使用多个互相正交地策略（事务性内存，竞争感知、动态适应的锁树等）来同时达到高竞争时地高吞吐和低竞争时地低时延。HMCS-T保持了HMCS的高性能，并且通过超时机制来使HMCS具备放弃竞争特性从而控制竞争者数量避免无意义的空转等待。由于基于队列地MCS锁相比自旋锁、门票锁等在高度竞争地场景下具有性能好，可扩展性好，并且保证公平性等优点，所有大多数层级锁中将MCS锁作为其各层地基本锁。上述层级锁具有不同地其他方面地特征和创新，但它们都是通过竞争分割降低锁地跨节点传递频率来提高锁地整体吞吐率的。

\subsection{本节小结}
锁是共享内存的多线程应用中保护关键共享数据使其只能被互斥访问的一种主要的软件实现的同步机制，其在硬件方面主要依赖于缓存一致性协议及原子操作等。不同的锁设计方案实现互斥的机制不同，使用的缓存一致性操作也不同，所以其在吞吐率、时延、可扩展性和公平性方面各有不同，在不同应用场景下的表现也不同。在传统的非NUMA架构下，简单的自旋锁适合竞争线程少竞争强度小的简单场景；门票锁保证了公平性但可扩展性较差，适合竞争强度稍大的场景；基于队列的锁（MCS锁，CLH锁）在竞争线程多竞争激烈的场景中性能、扩展性和公平性等方面都优于自旋锁和门票锁等。而在NUMA架构下，由于跨节点的缓存一致性操作通常比同一节点内的时延多数倍，而传统锁不能感知硬件层面的NUMA因素，所以频繁的跨节点锁传递使得传统锁的性能严重衰退，针对该问题，目前的解决方案主要集中在线程调度/放置，NUMA感知，委托执行等。其中NUMA感知的层级锁通过牺牲短期公平性来改变锁的传递顺序充分利用数据访问的局部性获取更好性能，另外获得更好的扩展性等其他方面的特性，大多数层级锁中都将基于队列的MCS或者CLH锁作为其各层的基本的锁。
\section{研究内容和结构安排}
如上节提到的，针对NUMA架构下传统锁频繁跨节点传递导致的性能严重下降的问题，现有的主流的解决方案主要集中在两个方面：1）通过线程迁移/放置来降低跨节点锁传递比例；2）通过NUMA感知改变原有锁的传递顺序从而减小锁的跨节点传递，主要代表是基于队列的层级锁。本文的研究在基于队列的层级锁基础上，发现其存在严重的长期公平性不足等问题，进一步的分析发现层级锁的性能和长期公平性都与线程调度/放置有很大关系，所以本文的研究主要通过更合理的线程放置/调度机制来使层级锁获取更高的性能和更好的长期公平性。

\subsection{层级锁中现有线程调度策略}
本文针对层级锁的性能和长期公平性受线程放置/调度策略影响较大的特点，通过分析现有线程调度策略的优缺点，在此基础上充分利用现有策略的优势，改进其不足，从而从线程放置的角度进一步地优化层级锁，使其能够同时保证高性能和稳定可靠地长期公平性，更好地满足NUMA架构下相关应用场景地需求。层级锁中现有地线程放置策略主有以下三种：自由放置（free-range），紧凑放置（compact）和平均放置（even）。

自由放置，即操作系统调度器的默认线程调度策略。应用程序对于线程地放置没有任何限制，线程的迁移调度全部交给操作系统地调度器来完成。自由放置能够充分利用现代操作系统激进的线程迁移来达到更好负载均衡和其他调度策略。但是对于层级锁来说，由于默认的调度器并不知道线程和应用程序大的所属关系，也不知道线程之间的锁竞争关系，简单的负载均衡很容易将同一个应用的线程分散到多个节点上去从而减少层级锁所能挖掘利用的局部性，同时也可能带来锁的持有者被抢占或者等待者被抢占等问题，从而导致性能方面的严重损失。

紧凑放置，由于层级锁偏向于寻找最近的等待者完成锁传递，因此最自然的线程放置策略是将线程尽可能地放得紧凑，这也是目前大多数层级锁中的默认线程放置策略。具体来说，新的线程会尽可能地被放置在当前NUMA节点地某个可用计算核心上，只有当前地NUMA节点上没有可用地计算核心时，新的线程才会被放置到一个新NUMA节点地某个专用计算核心上。相比操作系统默认地线程调度策略，紧凑策略更好地控制了CPU资源地分配，保存了更多地局部性，够获得尽可能高地性能；同时将每个线程绑定到一个专用的核上也能避免线程抢占带来的问题。但是，紧凑策略会导致线程在NUMA节点之间分布的不均，再加上层级锁锁传递策略的本地偏好的特性，进而不能保证层级锁地长期公平性（long-term fairness），即从长远看系统总的吞吐率很高，但是单个线程的吞吐率之间差异很大。

平均放置，另一种主要的线程放置策略是平均放置，也就是说线程被平均地放置在所有的NUMA节点上。由于每个节点上运行相同数量的线程，所以每个节点具有相同的将锁保持在其上的能力，因此平均放置地策略能够很好地保证层级锁地长期公平性。但是在锁地竞争不足时相比紧凑策略会有很大地吞吐率损失。这主要是因为平均放置使得线程分布更为分散，而相同的竞争能力又使得锁很容易在NUMA节点之间随意传递，所以在竞争不足时层级锁不能有效地挖掘同一个NUMA节点上地线程之间地局部性。

\subsection{竞争感知的混合调度框架}
性能和公平性是任何锁设计中最重要的两个指标，而目前的层级锁设计及其线程放置策略或者不能保证最佳的性能，或者不能保证线程之间的长期公平性，或者只能在高竞争的情况下同时保证性能和公平性。究其原因主要有两点：1）现有线程放置策略本身存在局限性；2）单个线程放置策略难以满足复杂多变的应用竞争状况。对于公有云等很多应用场景来说，为了给用户提供按需付费的服务并且高效地利用计算、存储等资源，性能和公平性对于其地成功都是至关重要地\cite{rao2014towards}；另外，很多大型应用中线程之间对于共享资源的竞争是不可预测和控制的，通常情况下竞争很小的一块共享数据可能会突然变得高度竞争，比如搜索引擎中突然出现的热门事件的搜索\cite{chabbi2016contention}。所以为了适应这些复杂应用场景的需求，现有的基于队列的层级锁的线程放置策略必须要先解决上述两个缺陷/挑战。

鉴于此，本文的研究首先针对紧凑放置不能保证长期公平性和平均放置性能较差的问题对其分别做了改进，对应得到以下两种新策略，加强的平均放置（restricted even）和有轮换的紧凑放置（compact with shift）
\begin{itemize}
\item 加强的平均放置。为了尽可能地保证平均放置的性能，我们限制该策略所能是使用地NUMA节点数为能满足需要地最少地节点数，而不是全部可用地节点数。相比原有的平均放置策略，新的策略在保证长期公平性地同时尽可能地保存局部性是层级锁能尽可能地挖掘局部性从而保证高性能，然而相比紧凑放置，新的策略在某些情况（竞争强度不足）下还是会有相当的性能损失。
\item 有轮换地紧凑放置。我们发现紧凑放置之后每个线程的吞吐率是由其所运行的位置决定的，所以在紧凑放置地基础上，引入了轮换（shift）机制，即通过定期地交换线程的位置来抹平线程的吞吐率之间的差异从而保证长期公平性。在有轮换的紧凑放置策略中，轮换的频率决定了最终的长期公平性的好坏。
\end{itemize}
基于上述两种改进后的策略及应用程序竞争状况复杂多变的特征，我们提出了竞争感知地混合放置框架（contention-aware hybrid）MSS。相比现有的单一固定的线程放置策略，MSS主要有以下几个特征：
\begin{itemize}
\item 竞争感知，该框架通过取样检测锁事件来评估当前地竞争状况，从而能够适应复杂多变的程序竞争状况。其中锁事件是每个线程与锁相关地操作（请求锁，拿锁，放锁）。
\item 混合，该框架可以被看作是有轮换的紧凑放置和加强的平均放置的混合体，在竞争强度足够的情况下应用加强的混合放置否则应用有轮换的紧凑放置策略，最终的目的是用最小的代价同时保证层级锁的性能和长期公平性。
\item 动态，该框架按照应用中层级锁的复杂多变的竞争状况动态地应用合适地线程放置策略。
\end{itemize}

在特定地应用中特定的竞争状况下，为了确定一个最合适线程放置策略，我们从Malthusian锁中引入了饱和点（saturation point）的概念。饱和点是能保证某个线程放锁时总有至少一个其余线程在等锁的最小线程数。我们的线程放置框架偏向于应用加强的平均放置策略，因为相比有轮换的紧凑放置策略它没有课外的线程迁移开销。针对某个特定的竞争状况，如果采用加强的平均放置策略后，每个NUMA节点上的线程数大于等于饱和点，则能在保证长期公平性的情况下获取高性能，所以应用加强的平均放置策略，否则应用有轮换的紧凑放置策略。
\subsection{结构安排}
本文共分为五个章节，具体如下：

第一章为绪论，主要概括介绍了本文的研究背景、意义及本文的研究内容。本文大的研究大背景主要是NUMA架构带来的新的机遇和挑战，尤其是NUMA架构给现有锁设计带来的挑战。本文的研究基于NUMA感知的层级锁，分析了现有层级锁中线程放置策略对性能和长期公平性的影响，对现有线程放置策略进行了改进并提出了一种竞争感知的混合的能够更好适合NUMA架构和复杂多变的应用的线程放置框架。

第二章介绍了相关研究和技术

第三章首先通过实验展示了现有线程放置策略在层级锁性能和长期公平性方面的表现优劣，然后通过对单个线程的吞吐率建模分析了线程放置策略中影响性能和长期公平性的根本因素，在此基础上得出了层级锁的线程放置方案设计中应该遵循的原则和面临的挑战。

第四章详细阐述了本文研究的竞争感知的混合线程放置框架MSS的架构设计和实现。其中MSS的设计方面包括基本的设计思路即MSS如何解决现有线程放置方案存在的缺陷、MSS的架构，及对MSS中引入相关机制额外开销的讨论。MSS的实现主要包含了线程迁移，策略切换等的实现细节。

第五章通过实验验证MSS的有效性。

第六章对全文总结。
\section{本章小结}
本章首先介绍了NUMA架构的基本特征及其对于多线程高性能软件设计尤其是锁带来的机遇和挑战，然后介绍了锁的演化及现有研究针对传统锁在NUMA架构下性能下降所做的改进（主要是层级锁），接着分析了现有层级锁中线程放置策略存在的优缺点，最后基于现有线程放置策略相应提出了本文的研究内容：层级锁中竞争感知的混合线程放置框架。